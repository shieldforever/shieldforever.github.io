---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

You can also find my articles on <u><a href="https://scholar.google.com/citations?hl=zh-CN&user=635o82sAAAAJ">my Google Scholar profile</a>.</u>

--------

Exploiting Temporal-Unrolled Parallelism for Energy-Efficient SNN Acceleration
<br>
Fangxin Liu, Zongwu Wang, Wenbo Zhao, Ning Yang, Yongbiao Chen, Shiyuan Huang, **Haomin Li**, Tao Yang, Songwen Pei,Xiaoyao Liang,and Li Jiang
<br>
IEEE Transactions on Parallel and Distributed Systems ( <b><font color="#2a9d8f">TPDS'24 </font></b> )

--------

INSPIRE: Accelerating Deep Neural Networks via Hardware-friendly Index-Pair Encoding
<br>
Fangxin Liu, Ning Yang, Zhiyan Song, Zongwu Wang, **Haomin Li**, Shiyuan Huang, Zhuoran Song, Songwen Pei and Li Jiang
<br>
61th Design Automation Conference ( <b><font color="#2a9d8f">DAC'24 </font></b> )

--------

EOS: An Energy-Oriented Attack Framework for Spiking Neural Networks
<br>
Ning Yang, Fangxin Liu, Zongwu Wang, **Haomin Li**, Zhuoran Song, Songwen Pei and Li Jiang
<br>
61th Design Automation Conference ( <b><font color="#2a9d8f">DAC'24 </font></b> )

--------

DEFA: Efficient Deformable Attention Acceleration via Pruning-Assisted Grid-Sampling and Multi-Scale Parallel Processing
<br>
Yansong Xu, Dongxu Lyu, Zhenyu Li, Yuzhou Chen, Zilong Wang, Gang Wang, Zhican Wang, **Haomin Li** and Guanghui He
<br>
61th Design Automation Conference ( <b><font color="#2a9d8f">DAC'24 </font></b> )

--------

SPARK: Scalable and Precision-Aware Acceleration of Neural Networks via Efficient Encoding
<br>
Fangxin Liu, Ning Yang, **Haomin Li**, Zongwu Wang, Zhuoran Song, Songwen Pei, Li Jiang
<br>
30th International Symposium on High-Performance Computer Architecture ( <b><font color="#2a9d8f">HPCA'24 </font></b> )

--------

PAAP-HD: PIM-Assisted Approximation for Efficient Hyper-Dimensional Computing
<br>
Fangxin Liu=, **Haomin Li=**, Ning Yang, Yichi Chen, Zongwu Wang, Tao Yang, Li Jiang
<br>
29th Asia and South Pacific Design Automation Conference ( <b><font color="#2a9d8f">ASPDAC'23 </font></b> )

--------

TEAS: Exploiting Spiking Activity for Temporal-wise Adaptive Spiking Neural Networks
<br>
Fangxin Liu=, **Haomin Li=**, Ning Yang, Zongwu Wang, Tao Yang, Li Jiang
<br>
29th Asia and South Pacific Design Automation Conference ( <b><font color="#2a9d8f">ASPDAC'23 </font></b> )

--------

TSTC: Enabling Efficient Training via Structured Sparse Tensor Compilation
<br>
Shiyuan Huang=, Fangxin Liu=, Tian Li, Zongwu Wang, **Haomin Li**, Li Jiang
<br>
29th Asia and South Pacific Design Automation Conference ( <b><font color="#2a9d8f">ASPDAC'23 </font></b> )

--------

HyperFeel: An Efficient Federated Learning Framework Using Hyperdimensional Computing
<br>
**Haomin Li=**, Fangxin Liu=, Yichi Chen, Li Jiang
<br>
29th Asia and South Pacific Design Automation Conference ( <b><font color="#2a9d8f">ASPDAC'23 </font></b> )

--------

HyperNode: An Efficient Node Classification Framework Using HyperDimensional Computing
<br>
**Haomin Li=**, Fangxin Liu=, Yichi Li, Li Jiang
<br>
42th IEEE/ACM International Conference on Computer-Aided Design ( <b><font color="#2a9d8f">ICCAD'23 </font></b> )

--------

HyperAttack: An Efficient Attack Framework for HyperDimensional Computing
<br>
Fangxin Liu=, **Haomin Li=**, Yongbiao Chen, Tao Yang, Li Jiang
<br>
60th Design Automation Conference ( <b><font color="#2a9d8f">DAC'23 </font></b> )

--------

L3E-HD: A Framework Enabling Efficient Ensemble in High-Dimensional Space for Language Tasks
<br>
Fangxin Liu, **Haomin Li**, Xiaokang Yang,Li Jiang
<br>
45th International ACM SIGIR Conference on Research and Development in Information Retrieval (<b><font color="#2a9d8f">SIGIR'23 </font></b>'22)
<br>
[code](https://github.com/MXHX7199/SIGIR22-EnsembleHDC)
[link](https://dl.acm.org/doi/abs/10.1145/3477495.3531761)

--------

DeepSE: Detecting super-enhancers among typical enhancers using only sequence feature embeddings
<br>
Qiao-Ying Ji, Xiu-Jun Gong, **Haomin Li**, Pu-Feng Du; 
<br>
Genomics, 113(6): 4052-4060.

<!-- {% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->
